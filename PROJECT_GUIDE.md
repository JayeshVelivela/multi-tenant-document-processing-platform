# Project Guide: Multi Tenant Document Processing Platform

## What This Project Is

This is a **production-grade backend system** that demonstrates real-world software engineering skills. It's not a toy projectâ€”it's built to the same standards you'd see at top tech companies.

### Core Functionality

The platform allows **multiple companies (tenants)** to:
1. **Upload documents** (PDFs, images, etc.)
2. **Process them asynchronously** in the background
3. **Extract metadata** (text, entities, structured data)
4. **Query and retrieve** processed documents securely

Think of it like a simplified version of:
- **DocuSign** (document processing)
- **Dropbox Business** (multi-tenant file storage)
- **AWS Textract** (document analysis)

## Why This Helps With Recruiting

### ðŸŽ¯ What Recruiters & Engineers Look For

When you're applying for SWE internships or new grad positions, reviewers want to see:

1. **Can you build real systems?** âœ…
   - This shows you understand architecture, not just algorithms
   - Demonstrates you can work with databases, APIs, background jobs

2. **Do you know industry practices?** âœ…
   - Authentication (JWT), multi-tenancy, async processing
   - Docker, migrations, testing, logging
   - All things you'll use in real jobs

3. **Can you write production code?** âœ…
   - Error handling, validation, security
   - Clean architecture, separation of concerns
   - Not just "it works," but "it's maintainable"

4. **Do you understand scale?** âœ…
   - Multi-tenancy (data isolation)
   - Background processing (async jobs)
   - Database design and indexing

### ðŸ’¼ How to Present This in Interviews

**"I built a multi-tenant document processing platform that demonstrates..."**

- **Backend Architecture**: Clean separation of API, service, and data layers
- **Security**: JWT authentication, tenant isolation, password hashing
- **Scalability**: Async job processing, database optimization
- **Production Readiness**: Docker, migrations, testing, logging, error handling

**Key Talking Points:**
- "I implemented row-level security for tenant isolation"
- "I designed an async processing pipeline using Redis queues"
- "I used Docker Compose for local development and deployment"
- "I wrote comprehensive tests and followed best practices"

## How to Use the Project

### Quick Start

```bash
# 1. Start everything
make up

# 2. Run migrations
make migrate

# 3. Seed sample data
make seed

# 4. Access the API
# Open: http://localhost:8000/docs
```

### Step-by-Step Usage

#### 1. **Register a New User**

```bash
curl -X POST http://localhost:8000/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "yourname@example.com",
    "password": "password123",
    "full_name": "Your Name",
    "tenant_name": "Your Company"
  }'
```

This creates:
- A new user account
- A new tenant (company)
- Associates the user with that tenant

#### 2. **Login and Get Token**

```bash
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "yourname@example.com",
    "password": "password123"
  }'
```

**Response:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

**Save the token!** You'll need it for authenticated requests.

#### 3. **Upload a Document**

```bash
# Replace YOUR_TOKEN with the token from step 2
curl -X POST http://localhost:8000/api/v1/documents/upload \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@/path/to/your/document.pdf"
```

**What happens:**
1. File is saved to tenant-specific storage
2. Document record created in database
3. Processing job enqueued in Redis
4. API returns immediately (async processing)

**Response:**
```json
{
  "id": 1,
  "filename": "abc123.pdf",
  "original_filename": "document.pdf",
  "status": "pending",
  "created_at": "2024-01-15T10:30:00Z"
}
```

#### 4. **Check Document Status**

```bash
# Wait a few seconds, then check status
curl -X GET http://localhost:8000/api/v1/documents/1 \
  -H "Authorization: Bearer YOUR_TOKEN"
```

**Response (after processing):**
```json
{
  "id": 1,
  "filename": "abc123.pdf",
  "status": "completed",
  "extracted_metadata": {
    "page_count": 1,
    "word_count": 150,
    "language": "en",
    "document_type": "invoice",
    "entities": {
      "dates": ["2024-01-15"],
      "amounts": ["$1,234.56"]
    }
  },
  "processed_at": "2024-01-15T10:30:05Z"
}
```

#### 5. **List All Documents**

```bash
# List all documents for your tenant
curl -X GET "http://localhost:8000/api/v1/documents/?page=1&page_size=20" \
  -H "Authorization: Bearer YOUR_TOKEN"

# Filter by status
curl -X GET "http://localhost:8000/api/v1/documents/?status=completed" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### Using the Interactive API Docs

**Easiest way to test:**

1. Open http://localhost:8000/docs in your browser
2. Click "Authorize" button (top right)
3. Login via `/api/v1/auth/login` endpoint
4. Copy the `access_token` from response
5. Paste it in the "Authorize" dialog
6. Now you can test all endpoints with the UI!

### Testing Multi-Tenancy

**This is the cool part!** The system enforces tenant isolation:

1. **Create two different tenants:**
   ```bash
   # User 1: Company A
   curl -X POST http://localhost:8000/api/v1/auth/register \
     -d '{"email": "user1@companya.com", "password": "pass123", "tenant_name": "Company A"}'
   
   # User 2: Company B  
   curl -X POST http://localhost:8000/api/v1/auth/register \
     -d '{"email": "user2@companyb.com", "password": "pass123", "tenant_name": "Company B"}'
   ```

2. **Upload documents as each user:**
   - User 1 uploads a document â†’ only User 1 can see it
   - User 2 uploads a document â†’ only User 2 can see it
   - **They can't see each other's data!** (Tenant isolation)

3. **Verify isolation:**
   - Login as User 1, list documents â†’ only see Company A's docs
   - Login as User 2, list documents â†’ only see Company B's docs

## Architecture Highlights

### What Makes This Production-Grade

1. **Multi-Tenancy**
   - Every user belongs to one tenant
   - All queries filter by `tenant_id`
   - Data physically isolated (can't leak between tenants)

2. **Async Processing**
   - Upload returns immediately
   - Background worker processes documents
   - Status tracking (pending â†’ processing â†’ completed/failed)

3. **Security**
   - JWT authentication
   - Password hashing (bcrypt)
   - Role-based access control
   - Input validation (Pydantic)

4. **Scalability**
   - Database indexes for performance
   - Redis queue for job processing
   - Can scale workers horizontally

5. **Production Features**
   - Docker containerization
   - Database migrations (Alembic)
   - Structured logging
   - Error handling
   - Rate limiting
   - Unit tests

## Real-World Use Cases

This architecture pattern is used by:

- **SaaS Platforms**: Stripe, Slack, Notion (multi-tenant)
- **Document Processing**: DocuSign, Adobe Acrobat
- **File Storage**: Dropbox Business, Google Drive
- **Content Management**: Contentful, Sanity

## What to Highlight in Your Resume/Interviews

### Resume Bullet Points

```
â€¢ Built a multi-tenant document processing platform using FastAPI, PostgreSQL, and Redis
â€¢ Implemented secure authentication with JWT and tenant isolation at the data layer
â€¢ Designed async document processing pipeline with background workers and job queues
â€¢ Containerized application with Docker and wrote comprehensive unit tests
â€¢ Applied production best practices: migrations, logging, error handling, rate limiting
```

### Interview Talking Points

**"Tell me about a project you built":**

> "I built a multi-tenant document processing platform that demonstrates production-grade backend engineering. The system allows multiple companies to upload documents, which are processed asynchronously in the background to extract metadata.
>
> I implemented several key features:
> - **Multi-tenancy**: Each company's data is completely isolated using row-level security
> - **Async processing**: Documents are queued in Redis and processed by background workers
> - **Security**: JWT authentication, password hashing, and tenant isolation
> - **Scalability**: Database indexes, connection pooling, and horizontal worker scaling
>
> The architecture follows clean separation of concerns with API, service, and data layers. I used Docker for containerization, Alembic for migrations, and wrote comprehensive tests. This demonstrates my ability to build systems that would work in a production environment."

## Next Steps for Enhancement

If you want to make this even more impressive:

1. **Add more document types**: Support images, Word docs, etc.
2. **Real OCR**: Integrate Tesseract or AWS Textract
3. **File storage**: Migrate to S3 instead of local filesystem
4. **Monitoring**: Add Prometheus metrics
5. **CI/CD**: Set up GitHub Actions
6. **Frontend**: Build a React/Vue frontend
7. **Deployment**: Deploy to AWS/GCP

## Common Questions

**Q: Is this overkill for a portfolio project?**  
A: No! This shows you understand real-world systems. Many candidates only have toy projects.

**Q: What if I don't understand everything?**  
A: That's fine! Focus on the parts you built. Be honest about what you learned.

**Q: Should I deploy this?**  
A: Yes! Deploying to AWS/GCP shows you can ship code. Use the free tier.

**Q: Can I add features?**  
A: Absolutely! Adding features shows initiative and problem-solving.

## Summary

This project demonstrates:
- âœ… Real backend architecture
- âœ… Industry-standard practices
- âœ… Production-ready code
- âœ… Understanding of scale and security

**It's not just codeâ€”it's proof you can build systems that matter.**

