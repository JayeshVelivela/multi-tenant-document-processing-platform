# Multi Tenant Document Processing Platform

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

A production-grade, multi-tenant document processing platform that demonstrates enterprise-level backend engineering practices. Built with FastAPI, PostgreSQL, and Redis, this system showcases real-world software engineering skills suitable for SWE internship and new grad positions.

## ğŸŒŸ What This Project Does

This platform allows **multiple companies (tenants)** to securely upload documents, process them asynchronously, and extract structured metadata. Think of it as a simplified version of services like:

- **DocuSign** - Document processing and analysis
- **Dropbox Business** - Multi-tenant file storage with metadata
- **AWS Textract** - Document text and data extraction
- **Invoice2go** - Invoice processing and data extraction

### Why Extract Metadata?

Metadata extraction transforms unstructured documents into searchable, queryable data. Here are real-world use cases:

#### ğŸ“„ **Invoice Processing**
- Extract: Amounts, dates, vendor names, line items
- Use case: Automate accounts payable, expense tracking, financial reporting
- Example: Upload an invoice â†’ Get structured data â†’ Auto-populate accounting system

#### ğŸ“‹ **Contract Analysis**
- Extract: Key dates, parties, terms, obligations
- Use case: Legal document review, contract management, compliance tracking
- Example: Upload contract â†’ Extract expiration dates â†’ Set reminders

#### ğŸ“ **Form Processing**
- Extract: Filled fields, signatures, dates
- Use case: Application processing, survey analysis, data entry automation
- Example: Upload application form â†’ Extract applicant info â†’ Populate database

#### ğŸ” **Document Search & Discovery**
- Extract: Full text, keywords, entities
- Use case: Make documents searchable, content discovery, knowledge management
- Example: Upload documents â†’ Extract text â†’ Enable full-text search

#### ğŸ“Š **Compliance & Auditing**
- Extract: Regulated information, dates, amounts
- Use case: Regulatory compliance, audit trails, financial reporting
- Example: Upload financial documents â†’ Extract amounts â†’ Generate reports

#### ğŸ¤– **Automation & Integration**
- Extract: Structured data from unstructured documents
- Use case: Integrate with other systems, automate workflows, reduce manual work
- Example: Upload receipt â†’ Extract expense data â†’ Send to accounting software

**In this demo**, the system extracts:
- Page count, word count, language
- Document type (invoice, contract, etc.)
- Extracted text preview
- Entities (dates, amounts, company names)

## ğŸš€ Features

### âœ… Multi-Tenancy
- Complete data isolation between companies
- Row-level security enforced at database layer
- Tenant-specific file storage

### âœ… Asynchronous Processing
- Background workers process documents
- Non-blocking API responses
- Job queue management with Redis

### âœ… Security
- JWT-based authentication
- Password hashing with bcrypt
- Role-based access control (Admin, User, Viewer)
- Input validation and rate limiting

### âœ… Production-Ready
- Docker containerization
- Database migrations (Alembic)
- Comprehensive unit tests
- Structured JSON logging
- Error handling middleware

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Client Applications                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP/REST
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Layer (FastAPI)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Auth   â”‚  â”‚Document  â”‚  â”‚Middlewareâ”‚            â”‚
â”‚  â”‚   API    â”‚  â”‚   API    â”‚  â”‚          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service    â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚
â”‚    Layer     â”‚  â”‚    Layer     â”‚  â”‚    Layer     â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Auth Service â”‚  â”‚ Document     â”‚  â”‚ Tenant       â”‚
â”‚              â”‚  â”‚ Service      â”‚  â”‚ Service      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Data Access    â”‚
                â”‚     Layer       â”‚
                â”‚  (SQLAlchemy)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚  â”‚    Redis     â”‚  â”‚ File Storage â”‚
â”‚   Database   â”‚  â”‚   (Queue)    â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Job Queue
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Worker     â”‚
                â”‚   Process    â”‚
                â”‚ (Background) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Backend** | FastAPI | High-performance async API framework |
| **Database** | PostgreSQL | Relational database with JSON support |
| **ORM** | SQLAlchemy | Database abstraction and migrations |
| **Queue** | Redis + RQ | Background job processing |
| **Auth** | JWT | Stateless authentication |
| **Validation** | Pydantic | Request/response validation |
| **Testing** | pytest | Unit and integration tests |
| **Containerization** | Docker | Development and deployment |

## ğŸ“¦ Getting Started

### Prerequisites

- Docker and Docker Compose
- Make (optional, for convenience commands)

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd "Multi Tenant Deocument Processing Platform"
   ```

2. **Create environment file**
   ```bash
   cp .env.example .env
   ```

3. **Start all services**
   ```bash
   make up
   # Or: docker-compose up -d
   ```

4. **Run database migrations**
   ```bash
   make migrate
   ```

5. **Seed sample data**
   ```bash
   make seed
   ```

6. **Access the API**
   - **API Base**: http://localhost:8000
   - **Interactive Docs**: http://localhost:8000/docs
   - **ReDoc**: http://localhost:8000/redoc

### Quick Test

```bash
# 1. Register a user
curl -X POST http://localhost:8000/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "demo@example.com",
    "password": "password123",
    "full_name": "Demo User",
    "tenant_name": "Demo Company"
  }'

# 2. Login
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "demo@example.com", "password": "password123"}'

# 3. Upload a document (use token from step 2)
curl -X POST http://localhost:8000/api/v1/documents/upload \
  -H "Authorization: Bearer YOUR_TOKEN_HERE" \
  -F "file=@/path/to/document.pdf"
```

## ğŸ“š API Documentation

### Authentication

- `POST /api/v1/auth/register` - Register new user
- `POST /api/v1/auth/login` - Login and get JWT token
- `GET /api/v1/auth/me` - Get current user info

### Documents

- `POST /api/v1/documents/upload` - Upload document
- `GET /api/v1/documents/` - List documents (with pagination)
- `GET /api/v1/documents/{id}` - Get document details

**Full API documentation available at**: http://localhost:8000/docs

## ğŸ“Š Accessing Extracted Data

### Via Web Interface

1. **Dashboard**: View summary statistics (total, pending, processing, completed documents)
2. **Documents Page**: 
   - See all documents with their status
   - View extracted metadata for completed documents
   - Filter by status (all, pending, processing, completed, failed)
   - Download original files
   - See extracted entities (dates, amounts, companies)

### Via API

#### Get All Documents
```bash
GET /api/v1/documents/
Authorization: Bearer <your_token>
```

#### Get Specific Document with Metadata
```bash
GET /api/v1/documents/{document_id}
Authorization: Bearer <your_token>
```

#### Download Original File
```bash
GET /api/v1/documents/{document_id}/download
Authorization: Bearer <your_token>
```

### What Data is Extracted?

- **Basic Metadata**: Page count, word count, language, document type
- **Entities**: Dates, amounts (currency), company names
- **Text Preview**: First 200 characters of extracted text
- **Full Text**: Complete extracted text (stored in database)

### Using the Data

The extracted metadata can be used for:
- **Search & Organization**: Find documents by content, type, or entities
- **Business Intelligence**: Track invoices, analyze trends
- **Automation**: Integrate with accounting systems, CRMs
- **Compliance**: Audit trails, reporting

See **[DATA_ACCESS_GUIDE.md](DATA_ACCESS_GUIDE.md)** for detailed information on accessing data, use cases, and improvement opportunities.

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Or manually
docker-compose exec api pytest -v --cov=app
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # API routes
â”‚   â”œâ”€â”€ models/           # Database models
â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”œâ”€â”€ middleware/       # Logging, rate limiting
â”‚   â””â”€â”€ worker.py         # Background worker
â”œâ”€â”€ alembic/              # Database migrations
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ docker-compose.yml    # Docker setup
â””â”€â”€ requirements.txt     # Python dependencies
```

## ğŸŒ Making It Public

### Option 1: Deploy Backend to Free Hosting (Recommended)

#### Railway (Easiest)

1. **Sign up**: https://railway.app
2. **Create new project** â†’ "Deploy from GitHub repo"
3. **Add services**:
   - PostgreSQL (database)
   - Redis (queue)
   - Your API (from Dockerfile)
4. **Set environment variables** from `.env.example`
5. **Deploy** â†’ Get public URL

#### Render

1. **Sign up**: https://render.com
2. **New Web Service** â†’ Connect GitHub repo
3. **Settings**:
   - Build Command: `docker build -t app .`
   - Start Command: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
4. **Add PostgreSQL and Redis** services
5. **Deploy**

#### Fly.io

1. **Install flyctl**: `curl -L https://fly.io/install.sh | sh`
2. **Login**: `fly auth login`
3. **Launch**: `fly launch` (in project directory)
4. **Add PostgreSQL**: `fly postgres create`
5. **Add Redis**: `fly redis create`
6. **Deploy**: `fly deploy`

### Option 2: Create a Frontend + Deploy Both

Create a simple React/Vue frontend that calls your deployed API:

1. **Deploy backend** (using Option 1 above)
2. **Create frontend** in a separate repo
3. **Deploy frontend** to:
   - **Vercel** (https://vercel.com) - Free, easy
   - **Netlify** (https://netlify.com) - Free, easy
   - **GitHub Pages** - Free, static only

### Option 3: GitHub Pages (Frontend Only)

Since GitHub Pages only hosts static sites, you can:

1. **Deploy backend** to Railway/Render/Fly.io
2. **Create simple HTML/JS frontend** that calls your API
3. **Host frontend** on GitHub Pages
4. **Update CORS** in backend to allow your GitHub Pages domain

## ğŸ“ Sample Accounts

After running `make seed`, you can use:

- **Acme Corporation**: `admin@acme.com` / `admin123`
- **TechStart Inc**: `admin@techstart.com` / `admin123`
- **Global Industries**: `admin@global.com` / `admin123`

## ğŸ¯ Why This Project Matters

This project demonstrates:

- âœ… **Real backend architecture** (not just algorithms)
- âœ… **Industry best practices** (auth, security, testing)
- âœ… **Production-ready code** (error handling, logging, migrations)
- âœ… **Understanding of scale** (multi-tenancy, async processing)
- âœ… **Modern tech stack** (FastAPI, PostgreSQL, Docker)

**Perfect for**: SWE internships, new grad positions, backend engineering roles

## ğŸ¤ Contributing

This is a portfolio project, but suggestions and improvements are welcome!

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is created for educational and portfolio purposes.

## ğŸ‘¤ Author

Built as a demonstration of production-grade backend engineering practices.

---

**â­ If you find this project helpful, please give it a star!**
